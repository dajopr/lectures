{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZs0YMOEYHj6vU0qMZPW5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajopr/lectures/blob/main/image_processing/lecture_01_image_processing_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Image Processing in Python with colab\n",
        "\n",
        "This exercise sheet provides a hands-on introduction to image processing using Python, focusing on the core libraries:\n",
        "\n",
        "- OpenCV (cv2): For image and video manipulation.\n",
        "\n",
        "- NumPy: For efficient numerical operations on images (represented as arrays).\n",
        "\n",
        "- Matplotlib: For visualizing images and plotting results.\n",
        "\n",
        "Before you begin:\n",
        "\n",
        "Let's first get familiar with Colab\n",
        "1. Create a new code cell: Click the \"+ Code\" button above\n",
        "2. In the code cell you just created, type print(\"Hello, Colab!\") and then press Control+Enter to run the code.  The output will appear below the cell. Shift+Enter also runs the current cell, but also steps to the next cell.\n",
        "3. Upload an image.\n",
        "    - Open the files tab in the side bar.\n",
        "    - Select upload to session storage.\n",
        "    - Select a file from your computer to upload to the session. This will be discarded after the session is closed.\n",
        "    - You can also drag and drop files into the highlighted area at the bottom."
      ],
      "metadata": {
        "id": "BrowpNmU-htC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Make sure you have a Google Colab environment set up.\n",
        "\n",
        "    Install the necessary libraries (should be installed already)"
      ],
      "metadata": {
        "id": "FRVWKOYcc4DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiHkOt5I-xKi",
        "outputId": "6cecb962-7ad1-48de-88da-adb8a2748630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Import the necessary libraries"
      ],
      "metadata": {
        "id": "GuXrdoBD_s9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io"
      ],
      "metadata": {
        "id": "iqkANZc0_yoI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Image fundamentals\n",
        "\n",
        "### Exercise 1a – Loading an image\n",
        "\n",
        "1. Use cv2.imread(\"path/to/image\") to load an image from a file. Assign the image to a variable named image_original.\n",
        "\n",
        "You can upload a new image to your Colab environment or use the image added in the previous steps.\n",
        "\n",
        "Ignore any coloring issues. This will be address in the upcoming exercises.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hbrE236i_GIm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oiwO1MZT_-cb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1b – Image display\n",
        "\n",
        "1. Use plt.imshow(image_name) to display the image in the Colab notebook.\n",
        "2. Assign the current image display to a variable named **ax** with plt.gca() (get current axis)\n",
        "3. Turn off the x axis with ax.get_xaxis().set_visible(False)\n",
        "4. Turn off the y axis as well\n"
      ],
      "metadata": {
        "id": "nSBq6lC2fqGY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lN8MpenJgqij"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1c – Color spaces\n",
        "\n",
        "OpenCV loads images into BGR space by default while matplotlib expects images to be in RGB. To display the image correctly the color space needs to be changed.\n",
        "\n",
        "1. Convert the image to RGB and assign it to variable image_rgb\n",
        "    - Use OpenCV's \"convert color\" function cv2.cvtColor\n",
        "    - It takes two arguments:\n",
        "        1. The image to be converted (image_original)\n",
        "        2. An integer denoting the color space conversion\n",
        "    - Color space conversion codes are available as constants in the cv2 module\n",
        "    - For BGR to RGB use cv2.COLOR_BGR2RGB\n",
        "2. Display the converted image in colab natively by ending a codeblock with the name of the variable"
      ],
      "metadata": {
        "id": "XqKcWH1rjbeM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARxMmTf0kyed"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1d – Displaying multiple images\n",
        "\n",
        "Display the original image in BGR (which will look incorrect) and the RGB image side by side.\n",
        "\n",
        "1. Access the first subplot with plt.subplot\n",
        "    - The first two arguments define the number of rows and columns respectively.\n",
        "    - To display the images next to eachother use plt.subplot(1, 2, ...)\n",
        "    - The third argument selects the current subplot. In this case either 1 or 2. The indices start in the top right and first increase to the right and then down. So plt.subplot(2,3,4) would be the first subplot in the second row.\n",
        "2. Display the image in BGR using plt.imshow\n",
        "3. Set the title of the subplot with plt.title\n",
        "4. Repeat for the image in RGB"
      ],
      "metadata": {
        "id": "tKn9t6IMuNYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2v54EA_wTvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1e – Resizing an image\n",
        "\n",
        "1. Resize the image to size 224 px by 224 px\n",
        "    - Use cv2.resize() to change the dimensions of the image.\n",
        "2. Use with area and linear interpolation and display side by side\n",
        "    - For available interpolation methods see https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121\n",
        "    -"
      ],
      "metadata": {
        "id": "LQxmNLX8Ita1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VrJsvxPwQdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 - Images as arrays\n",
        "\n",
        "**Images as NumPy ndarrays**\n",
        "\n",
        "In the world of digital image processing, images are often represented as multi-dimensional arrays, or ndarrays, using the NumPy library in Python. This representation allows for efficient storage and manipulation of image data.\n",
        "\n",
        "Understanding the Structure\n",
        "\n",
        "- Grayscale Images: A grayscale image is typically represented as a 2D array. Each element in the array corresponds to the intensity of a pixel, with values ranging from 0 (black) to 255 (white). The shape of the array is (height, width).\n",
        "\n",
        "- Color Images: A color image, such as an RGB image, is represented as a 3D array. The first two dimensions represent the height and width of the image, while the third dimension represents the color channels. For RGB images, the third dimension has a size of 3, corresponding to the red, green, and blue color intensities. The shape of the array is (height, width, 3).\n",
        "\n",
        "### Exercise 2a – Accessing pixel values\n",
        "1. Print the shape of the image\n",
        "    - Use image.shape to access the shape\n",
        "1. Use NumPy array indexing to access the pixel value at a specific location (x, y) i.e. (50, 50).\n",
        "    - Values are accessed via square brackets e.g. image[y, x] access pixel at (x,y)\n",
        "    - Remember that in NumPy arrays, the first index is the row (y-coordinate), and the second index is the column (x-coordinate).\n",
        "2. Access a region of interest\n",
        "    - Multiple pixel values can be accessed by specifying a range image[y_start:y_end, x_start:x_end]\n",
        "    - Omitting one or both values selects all remaining values. E.g. image[:, :10] selects the first 10 columns.\n",
        "3. Set the first 10 rows to 0\n",
        "    - Use image[y_start:y_end, x_start:x_end] = value"
      ],
      "metadata": {
        "id": "5FwL8-6AxleL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvQb-MXIwOsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2b – Color channels\n",
        "The color channels of the image can be accessed individually.\n",
        "\n",
        "1. Display the red, green and blue channels next to eachother\n",
        "2. Display the channels with a different colormap\n",
        "    - In plt.imshow the colormap can be set by setting the keyword argument cmap\n",
        "    - For available default colormaps see https://matplotlib.org/stable/users/explain/colors/colormaps.html\n"
      ],
      "metadata": {
        "id": "GDvcdqme_eQT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRhFDrW4wLBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2c – Image arithmetic\n",
        "\n",
        "The numpy arrays that make up an image also support arithmetic operations.\n",
        "\n",
        "1. Convert the image to float\n",
        "    -\n",
        "2. Calculate the mean value of the green channel\n",
        "3. Subtract the mean value from the green channel in the image\n"
      ],
      "metadata": {
        "id": "zxCxffDNBELc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awE_ZJ3AwLiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Histogram equalization\n",
        "### Exercise 3a: Histogram Equalization with NumPy\n",
        "\n",
        "Objective: Implement and understand the histogram equalization algorithm using only NumPy for calculations and Matplotlib for visualization.\n",
        "\n",
        "Motivation: Histogram equalization is a fundamental technique for improving contrast in images, especially those where pixel values are clustered in a narrow range. This exercise will help you understand how it works step-by-step by manipulating histograms and cumulative distribution functions (CDFs).\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Loadimage: Start with a sample grayscale image represented as a NumPy array (a simple low-contrast example is provided in the code).\n",
        "    - Use io.imread(\"https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\") to load the low contrast image\n",
        "2. Convert the image to 0 - 1 range\n",
        "3. Calculate the original histogram\n",
        "    - Use np.histogram to get the intensity distribution of the original image.\n",
        "4. Plot this histogram using plt.plot\n",
        "5. Calculate the Original CDF\n",
        "    - Hint: The histogram values need to be cumulatively summed and then normalized.\n",
        "6. Plot the CDF\n",
        "\n",
        "7. Perform the equalization\n",
        "    - You can use np.interp (see https://numpy.org/doc/stable/reference/generated/numpy.interp.html) to map the cdf to the image\n",
        "    - Hint: If the shapes of the cdf and the bins don't match check the first and last bin returned by np.histogram - which is a valid value for an image\n",
        "\n",
        "8. Visualize Results: Display the original image and the equalized image side-by-side.\n",
        "9. Visualize the histogram and CDF of the qualized image\n",
        "10. Analyze: Compare the original and equalized histograms and images. How has the intensity distribution changed? How has the visual appearance improved? Observe the shape of the CDF."
      ],
      "metadata": {
        "id": "wc6wowSLtQX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = io.imread(\"https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\")"
      ],
      "metadata": {
        "id": "56v8eqmLtT-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3b: Histogram equalization with OpenCV\n",
        "\n",
        "Objective: Enhance the contrast of a color image using histogram equalization applied selectively to the luminance channel, preserving the original color information as much as possible.\n",
        "\n",
        "Motivation: Applying histogram equalization directly to each channel (R, G, B) of a color image often leads to unnatural color shifts and artifacts. By converting the image to a color space like YCbCr, which separates intensity (luminance – Y) from color information (chrominance – Cb, Cr), we can apply equalization only to the Y channel. This enhances the contrast based on brightness levels while keeping the color components (Cb, Cr) unchanged, resulting in a more natural-looking enhancement.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Load Image: Load the specified low-contrast color image from the provided URL (http://photography.bastardsbook.com/assets/content/images/large/florence-afternoon-_-7267492940.jpg)\n",
        "    - Note: io.imread loads images as RGB unlike opencv which defaults to BGR\n",
        "2. Equalize luminance of image\n",
        "    - Apply OpenCV's cv2.equalizeHist function only to the Y channel in YCbCr color space. Note that cv2.equalizeHist works on single-channel 8-bit images.\n",
        "\n",
        "3. Visualize Results: Display the original RGB image and the final equalized RGB image side-by-side using Matplotlib.\n",
        "\n",
        "4. Visualize Histograms (Optional but Recommended):\n",
        "    - Calculate and plot the histogram of the original Y channel.\n",
        "    - Calculate and plot the histogram of the equalized Y channel. This helps visualize the effect of the equalization step.\n",
        "\n",
        "5. Analyze:\n",
        "\n",
        "    - Compare the original and equalized images visually. How has the contrast changed?\n",
        "    - Do the colors in the equalized image look natural, or are there significant shifts?\n",
        "    - Compare the histograms of the original and equalized Y channels. How does the distribution change?\n",
        "    - Why is this YCbCr approach generally preferred for equalizing color images compared to applying equalizeHist to each R, G, and B channel independently?"
      ],
      "metadata": {
        "id": "n3c-n_nZtLq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = io.imread(\"http://photography.bastardsbook.com/assets/content/images/large/florence-afternoon-_-7267492940.jpg\")"
      ],
      "metadata": {
        "id": "qL2JAwGntcNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Image morphing (optional)\n",
        "\n",
        "Objective: Explore the effect of linear combination (cross-dissolving) as a simple image transition technique and understand the conditions under which it can produce a visually smooth effect, approximating a morph without complex warping.\n",
        "\n",
        "Motivation: While true image morphing often requires complex steps like feature matching and warping, a simple cross-dissolve can sometimes suffice if the source and destination images are very similar and perfectly aligned. This exercise demonstrates this basic technique and highlights the critical importance of image alignment and structural similarity for any morphing or transition effect. It serves as a contrast to more complex feature-based morphing methods.\n",
        "\n",
        "Key Concept:\n",
        "\n",
        "- Linear Combination / Cross-Dissolving: Creating an intermediate image by taking a weighted average of two input images. The formula is:\n",
        "    output_image = (1 - alpha) * image1 + alpha * image2\n",
        "    where alpha is a value between 0.0 and 1.0.\n",
        "\n",
        "    When alpha = 0.0, the output is identical to image1.\n",
        "\n",
        "    When alpha = 1.0, the output is identical to image2.\n",
        "\n",
        "    Values between 0 and 1 create a blend, effectively \"fading\" from image1 to image2 as alpha increases.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Find Suitable Image Pairs: This is the most crucial step for this specific exercise! Search for or create pairs of images that meet these criteria:\n",
        "\n",
        "    - Identical Subject & Viewpoint: The images should show the same scene or subject photographed from the exact same camera position. Using a tripod is ideal.\n",
        "\n",
        "    - Structural Alignment: Major shapes, lines, and features should be in the same location within both image frames.\n",
        "\n",
        "    - Allowed Differences: The images can differ in aspects like:\n",
        "\n",
        "        - Lighting (e.g., day vs. night, different artificial light).\n",
        "\n",
        "        - Color palette (e.g., different color grading or filters applied).\n",
        "\n",
        "        - Minor details (e.g., a person making a slightly different facial expression, clouds moving slightly, seasonal changes in foliage if the camera position is fixed).\n",
        "\n",
        "        - Texture or artistic style applied digitally.\n",
        "\n",
        "    - Same Dimensions: Both images must have the exact same height and width.\n",
        "\n",
        "    - Examples: Two photos from a fixed tripod at different times of day, two identical photos with different color filters applied, two frames from a static video where only lighting or a minor element changes.\n",
        "\n",
        "2. Load Images: Load your chosen pair of images (image1, image2) using a library like imageio. Double-check that their dimensions match.\n",
        "\n",
        "3. Implement Cross-Dissolve Function:\n",
        "\n",
        "    - Create a simple Python function, e.g., cross_dissolve(img1, img2, alpha).\n",
        "\n",
        "    - Inputs: The two images (as NumPy arrays) and the alpha value (between 0 and 1).\n",
        "\n",
        "    - Inside the function:\n",
        "\n",
        "        - Ensure images are converted to a floating-point type (e.g., float32) before multiplication to avoid overflow/clipping issues with uint8.\n",
        "\n",
        "        - Calculate output_image.\n",
        "\n",
        "        - Clip values to the valid range if necessary (though less likely if inputs are 0-255 and alpha is 0-1).\n",
        "\n",
        "        - Convert the resulting floating-point image back to the original data type (e.g., uint8) for display.\n",
        "\n",
        "        - Return the output_image.\n",
        "\n",
        "4. Generate and Visualize Intermediate Frames:\n",
        "\n",
        "    - Call your cross_dissolve function with several different alpha values (e.g., 0.25, 0.5, 0.75).\n",
        "\n",
        "    - Display the original image1, image2, and the generated intermediate frames using Matplotlib. Arrange them logically to show the transition.\n",
        "\n",
        "5. Analyze:\n",
        "\n",
        "    - Evaluate the smoothness of the transition for your chosen image pair. Why did the simple cross-dissolve work reasonably well (or not)? Relate this to the image selection criteria.\n",
        "\n",
        "    - What visual artifacts, if any, are still present (e.g., \"ghosting\" where elements aren't perfectly aligned)?\n",
        "\n",
        "    - Under what specific conditions is this simple linear combination technique sufficient for creating a transition effect?\n",
        "\n",
        "    - How does this compare to the feature-based morphing technique involving triangulation and warping? When would the more complex method be absolutely necessary?\n",
        "\n",
        "\n",
        "This exercise emphasizes the importance of input data quality (alignment and similarity) when choosing image processing techniques."
      ],
      "metadata": {
        "id": "U7-Y87nBtsUE"
      }
    }
  ]
}