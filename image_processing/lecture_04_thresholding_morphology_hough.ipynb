{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVXOT0TgbxBFtbyuEa/xfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajopr/lectures/blob/main/image_processing/lecture_04_thresholding_morphology_hough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise Sheet: Thresholding, Morphology, Connected Components & Hough Lines\n",
        "\n",
        "**Goal:** Apply thresholding, morphological operations, connected components analysis, and Hough line detection to solve practical image analysis tasks.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Run the following cells to import libraries, define helper functions, and set up image paths.\n",
        "**Important:** Make sure you have the necessary image files (`document.png`, `shapes_noisy.png`, `barcode.png`, `coins.png`, `tennis.png`) in the specified `IMAGE_DIR`. If running in Colab, upload them to the `images` folder."
      ],
      "metadata": {
        "id": "245Dj54SyW-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "# from google.colab.patches import cv2_imshow # Uncomment if using Colab\n",
        "def show_images(\n",
        "    images, titles, rows, cols, figsize=(15, 10), main_title=\"Image Comparison\"\n",
        "):\n",
        "    \"\"\"Helper function to display multiple images using Matplotlib\"\"\"\n",
        "    if not images:\n",
        "        print(\"No images to display.\")\n",
        "        return\n",
        "    if len(images) != len(titles):\n",
        "        print(\"Warning: Number of images and titles do not match.\")\n",
        "        min_count = min(len(images), len(titles))\n",
        "        images = images[:min_count]\n",
        "        titles = titles[:min_count]\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "    fig.suptitle(main_title, fontsize=16)\n",
        "\n",
        "    if rows * cols == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    plot_index = 0\n",
        "    for i, img in enumerate(images):\n",
        "        if plot_index < len(axes):\n",
        "            current_ax = axes[plot_index]\n",
        "            if img is not None:\n",
        "                if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):\n",
        "                    current_ax.imshow(img, cmap=\"gray\")\n",
        "                    current_ax.set_title(titles[i])\n",
        "                elif len(img.shape) == 3 and img.shape[2] == 3:\n",
        "                    current_ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                    current_ax.set_title(titles[i])\n",
        "                elif len(img.shape) == 3 and img.shape[2] == 4:\n",
        "                    current_ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA))\n",
        "                    current_ax.set_title(titles[i])\n",
        "                else:\n",
        "                    current_ax.set_title(f\"{titles[i]} (Unsupported Format)\")\n",
        "            else:\n",
        "                current_ax.set_title(f\"{titles[i]} (None)\")\n",
        "            current_ax.axis(\"off\")\n",
        "            plot_index += 1\n",
        "        else:\n",
        "            print(\n",
        "                f\"Warning: More images provided than subplot slots ({rows * cols}). Skipping '{titles[i]}'.\"\n",
        "            )\n",
        "\n",
        "    for j in range(plot_index, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nmrtFS3yqAD",
        "outputId": "03b5b33f-626d-415c-90c2-b3e3360ccebc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = \"./images\"  # Assumes an 'images' folder in the same directory as the script/notebook\n",
        "\n",
        "IMG_PATH_DOC = os.path.join(IMAGE_DIR, \"document.png\")\n",
        "IMG_PATH_NOISY = os.path.join(IMAGE_DIR, \"shapes_noisy.png\")\n",
        "IMG_PATH_BARCODE = os.path.join(IMAGE_DIR, \"barcode.png\")\n",
        "IMG_PATH_COINS = os.path.join(IMAGE_DIR, \"coins.png\")\n",
        "IMG_PATH_TENNIS = os.path.join(IMAGE_DIR, \"tennis.jpg\")\n",
        "\n",
        "# --- Check if image files exist ---\n",
        "required_image_paths = [\n",
        "    IMG_PATH_DOC,\n",
        "    IMG_PATH_NOISY,\n",
        "    IMG_PATH_BARCODE,\n",
        "    IMG_PATH_COINS,\n",
        "    IMG_PATH_TENNIS,\n",
        "]\n",
        "all_files_found = True\n",
        "if not os.path.exists(IMAGE_DIR):\n",
        "    print(\n",
        "        f\"ERROR: Image directory '{IMAGE_DIR}' not found. Please create it and add images.\"\n",
        "    )\n",
        "    all_files_found = False\n",
        "else:\n",
        "    print(f\"Checking for images in '{IMAGE_DIR}'...\")\n",
        "    for img_path in required_image_paths:\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"ERROR: Image file not found: {img_path}\")\n",
        "            all_files_found = False\n",
        "\n",
        "if all_files_found:\n",
        "    print(\"All required image files seem to be present.\")\n",
        "else:\n",
        "    print(\n",
        "        \"\\n!!! Please fix the missing image file issues before proceeding! Upload/place the required images. !!!\"\n",
        "    )\n",
        "def load_image(path, mode=cv2.IMREAD_COLOR):\n",
        "    if not all_files_found and not os.path.exists(path):\n",
        "        print(f\"Cannot load image {path}. File missing or directory issue.\")\n",
        "        return None\n",
        "    img = cv2.imread(path, mode)\n",
        "    if img is None:\n",
        "        print(f\"Error loading image {path} using OpenCV.\")\n",
        "    return img\n",
        "\n",
        "\n",
        "print(\"Image setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehQ1_gikytYa",
        "outputId": "ea767006-735f-410e-a020-c9b51bca7210"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for images in './images'...\n",
            "All required image files seem to be present.\n",
            "Image setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Comparing Thresholding Techniques\n",
        "\n",
        "**Objective:** Apply and compare Global, Otsu's, and Adaptive thresholding methods on an image, potentially with uneven illumination.\n",
        "\n",
        "**Instructions:**\n",
        "1. Load the `document.png` image in grayscale.\n",
        "2. Apply Global Thresholding using `cv2.threshold` with a manually chosen threshold value (e.g., 127). Use `cv2.THRESH_BINARY`.\n",
        "3. Apply Otsu's Binarization using `cv2.threshold`. Use `cv2.THRESH_BINARY + cv2.THRESH_OTSU` (the threshold value argument will be ignored).\n",
        "4. Apply Adaptive Thresholding using `cv2.adaptiveThreshold`. Try both `cv2.ADAPTIVE_THRESH_MEAN_C` and `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`. Choose appropriate `blockSize` (e.g., 11, 15 - must be odd) and `C` (e.g., 2, 5).\n",
        "5. Display the original grayscale image and all thresholded results using `show_images`.\n",
        "6. Answer the discussion questions."
      ],
      "metadata": {
        "id": "Iqd0i_UEzUi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Exercise 1: Comparing Thresholding ---\")\n",
        "\n",
        "img_doc = load_image(IMG_PATH_DOC, cv2.IMREAD_GRAYSCALE)\n",
        "# --- Student Code Starts Here ---\n",
        "\n",
        "# 1. Manual Global Thresholding\n",
        "manual_thresh_val = 127\n",
        "thresh_global = None # Replace with your code\n",
        "\n",
        "# 2. Otsu's Binarization\n",
        "\n",
        "thresh_otsu = None # Replace with your code\n",
        "\n",
        "# 3. Adaptive Thresholding (Mean)\n",
        "block_size_adapt = 15 # Must be odd\n",
        "C_adapt = 2\n",
        "thresh_adapt_mean = None # Replace with your result\n",
        "\n",
        "# 4. Adaptive Thresholding (Gaussian)\n",
        "\n",
        "thresh_adapt_gauss = None # Replace with your result\n",
        "\n",
        "# --- Student Code Ends Here ---\n",
        "\n",
        "# Display results\n",
        "images_ex1 = [img_doc, thresh_global, thresh_otsu, thresh_adapt_mean, thresh_adapt_gauss]\n",
        "titles_ex1 = [\"Original Grayscale\", f\"Global (Thresh={manual_thresh_val})\", \"Otsu's\", f\"Adaptive Mean (Block={block_size_adapt}, C={C_adapt})\", f\"Adaptive Gaussian (Block={block_size_adapt}, C={C_adapt})\"]\n",
        "show_images(images_ex1, titles_ex1, 2, 3, main_title=\"Exercise 1: Thresholding Comparison\") # Adjust rows/cols if needed\n"
      ],
      "metadata": {
        "id": "6qzValhZzQlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion Questions (Exercise 1):**\n",
        "1. How does the result of Otsu's method compare to your manually chosen global threshold? When would Otsu's be particularly useful?\n",
        "2. Compare the results of Adaptive Mean vs. Adaptive Gaussian thresholding. Are there noticeable differences?\n",
        "3. Why is Adaptive Thresholding often better than Global Thresholding for images like documents with potentially uneven lighting? What do the `blockSize` and `C` parameters control?"
      ],
      "metadata": {
        "id": "ZQZvYSRR0BIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Morphological Operations for Noise Removal\n",
        "\n",
        "**Objective:** Use Opening and Closing morphological operations to clean up \"salt and pepper\" noise in a binary image.\n",
        "\n",
        "**Instructions:**\n",
        "1. Load the `noisy_shapes.png` image. Assume it's already binary or threshold it if necessary (Otsu's might work well if it's grayscale with noise).\n",
        "2. Define a structuring element (kernel), for example, a 3x3 rectangle using `cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))`.\n",
        "3. Apply Morphological Opening (`cv2.MORPH_OPEN`) to the noisy image using `cv2.morphologyEx`. This should primarily remove \"salt\" (white) noise.\n",
        "4. Apply Morphological Closing (`cv2.MORPH_CLOSE`) to the noisy image using `cv2.morphologyEx`. This should primarily remove \"pepper\" (black) noise/holes.\n",
        "5. Apply Opening *followed by* Closing to the noisy image. Does this handle both types of noise effectively?\n",
        "6. Display the original noisy image and the results of Opening, Closing, and Opening+Closing using `show_images`.\n",
        "7. Answer the discussion questions."
      ],
      "metadata": {
        "id": "6kInxpEF0Hi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_noisy_gray = load_image(IMG_PATH_NOISY, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "# Assuming the loaded image might need thresholding to be truly binary\n",
        "ret, img_noisy_bin = cv2.threshold(img_noisy_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "print(\"Applied Otsu's threshold to noisy image.\")\n",
        "\n",
        "# --- Student Code Starts Here ---\n",
        "# 1. Define a structuring element (kernel)\n",
        "kernel_size = 3\n",
        "kernel = None # Replace with your kernel\n",
        "\n",
        "if kernel is not None:\n",
        "    # 2. Apply Morphological Opening\n",
        "    opened_img = None # Replace with your result\n",
        "\n",
        "    # 3. Apply Morphological Closing\n",
        "\n",
        "    closed_img = None # Replace with your result\n",
        "\n",
        "    # 4. Apply Opening then Closing\n",
        "\n",
        "    opened_then_closed_img = None # Replace with your result\n",
        "else:\n",
        "    print(\"Kernel not defined, cannot perform morphological operations.\")\n",
        "    opened_img, closed_img, opened_then_closed_img = None, None, None\n",
        "\n",
        "\n",
        "# --- Student Code Ends Here ---\n",
        "\n",
        "# Display results\n",
        "images_ex2 = [img_noisy_bin, opened_img, closed_img, opened_then_closed_img]\n",
        "titles_ex2 = [\"Original Noisy Binary\", f\"Opened (Kernel={kernel_size}x{kernel_size})\", f\"Closed (Kernel={kernel_size}x{kernel_size})\", \"Opened then Closed\"]\n",
        "show_images(images_ex2, titles_ex2, 2, 2, main_title=\"Exercise 2: Morphological Noise Removal\")\n"
      ],
      "metadata": {
        "id": "Zxv0s0HO0SXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion Questions (Exercise 2):**\n",
        "1. Explain what Morphological Opening primarily removes and why (in terms of erosion followed by dilation).\n",
        "2. Explain what Morphological Closing primarily removes/fills and why (in terms of dilation followed by erosion).\n",
        "3. Did applying Opening followed by Closing work better than either operation alone for this type of noise? Why or why not? How does changing the `kernel_size` affect the results?"
      ],
      "metadata": {
        "id": "OHDsJhzK0p7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Counting Objects using Connected Components\n",
        "\n",
        "**Objective:** Count the number of coins in an image using thresholding, optional morphological cleaning, and connected components analysis.\n",
        "\n",
        "**Instructions:**\n",
        "1. Load the `coins.png` image in grayscale.\n",
        "2. Threshold the image to create a binary representation where coins are foreground (white) and the background is black. Otsu's method is often suitable here.\n",
        "3. **Recommended:** Apply Morphological Opening (`cv2.MORPH_OPEN`) and/or Closing (`cv2.MORPH_CLOSE`) to the binary image to remove any small noise spots that might be counted as objects.\n",
        "4. Apply `cv2.connectedComponentsWithStats` to the cleaned binary image.\n",
        "5. Determine the number of coins by counting the number of labels found, remembering to **exclude the background label (label 0)**.\n",
        "6. Iterate through the `stats` array (from label 1 onwards). For each coin component, get its bounding box `(x, y, w, h)` and draw the box on the original *color* image (load it separately or convert grayscale). You can also draw the component label number near the box using `cv2.putText`.\n",
        "7. Display the thresholded image and the final image with bounding boxes and the count.\n",
        "8. Answer the discussion questions."
      ],
      "metadata": {
        "id": "oIb3CJ300qvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_coins_gray = load_image(IMG_PATH_COINS, cv2.IMREAD_GRAYSCALE)\n",
        "img_coins_color = load_image(IMG_PATH_COINS, cv2.IMREAD_COLOR) # For drawing\n",
        "\n",
        "img_draw_ex3 = img_coins_color.copy()\n",
        "\n",
        "# --- Student Code Starts Here ---\n",
        "\n",
        "# 1. Threshold the image\n",
        "# Note: If coins are darker than background, THRESH_BINARY_INV might be needed with Otsu.\n",
        "# Or, if coins are bright, THRESH_BINARY with Otsu.\n",
        "\n",
        "# If Otsu makes coins black and background white, invert it:\n",
        "# if np.mean(thresh_coins) > 127: # Heuristic: if most of the image is white after Otsu\n",
        "#    thresh_coins = cv2.bitwise_not(thresh_coins)\n",
        "thresh_coins = None # Replace\n",
        "\n",
        "# 2. Optional: Morphological Opening to remove noise\n",
        "\n",
        "binary_for_cc = thresh_coins # Use thresh_coins if no morphology\n",
        "\n",
        "num_coins = 0 # Initialize count\n",
        "\n",
        "if binary_for_cc is not None:\n",
        "    # 3. Connected Components Analysis\n",
        "\n",
        "    num_labels, labels_map, stats, centroids = 0, None, None, None # Replace\n",
        "\n",
        "    if stats is not None:\n",
        "        # 4. Count components (excluding background label 0)\n",
        "        num_coins = None # Replace\n",
        "\n",
        "        # 5. Draw bounding boxes and labels, filter by area\n",
        "        print(f\"Found {num_labels-1} potential coin(s) before area filtering. Drawing boxes...\")\n",
        "        min_coin_area = 200 # Adjust based on image and coin size\n",
        "        actual_coin_count = 0\n",
        "        for i in range(1, num_labels): # Iterate from 1 to exclude background\n",
        "            x = stats[i, cv2.CC_STAT_LEFT]\n",
        "            y = stats[i, cv2.CC_STAT_TOP]\n",
        "            w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "            h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "            area = stats[i, cv2.CC_STAT_AREA]\n",
        "\n",
        "            if area >= min_coin_area:\n",
        "                actual_coin_count += 1\n",
        "                cv2.rectangle(img_draw_ex3, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(img_draw_ex3, str(actual_coin_count), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "            else:\n",
        "               print(f\"  Component {i} rejected due to small area: {area}\")\n",
        "\n",
        "\n",
        "        num_coins = actual_coin_count # Update count after filtering\n",
        "        print(f\"Final count after area filtering: {num_coins}\")\n",
        "    else:\n",
        "        print(\"Connected components analysis failed.\")\n",
        "else:\n",
        "    print(\"Binary image for connected components is not available.\")\n",
        "\n",
        "\n",
        "# --- Student Code Ends Here ---\n",
        "\n",
        "# Display results\n",
        "images_ex3 = [img_coins_color, binary_for_cc if binary_for_cc is not None else np.zeros_like(img_coins_gray), img_draw_ex3]\n",
        "titles_ex3 = [\"Original Coins\", \"Binary Image for CC\", f\"Detected Coins: {num_coins}\"]\n",
        "show_images(images_ex3, titles_ex3, 1, 3, main_title=\"Exercise 4: Counting Coins\")\n"
      ],
      "metadata": {
        "id": "6qUkJPgs2Y_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion Questions (Exercise 3):**\n",
        "1. Why might you need `THRESH_BINARY_INV` sometimes when using Otsu's method, or why might you need to invert the result of Otsu's? (Hint: Consider whether the objects or the background are brighter).\n",
        "2. How did Morphological Opening (if used) help improve the accuracy of the count?\n",
        "3. What problem would occur if two coins were touching in the image? How might you attempt to separate them using morphological operations learned previously (e.g., Erosion, Watershed algorithm - though Watershed is more advanced)?\n"
      ],
      "metadata": {
        "id": "XTOQoDt32_l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Hough Line Transform for Line Detection\n",
        "\n",
        "**Objective:** Detect straight lines in tennis court image using the Probabilistic Hough Line Transform.\n",
        "\n",
        "**Instructions:**\n",
        "1. Load the `road_lanes.png` image in grayscale.\n",
        "2. Apply Canny edge detection (`cv2.Canny`) to find edges. You may need to tune the Canny thresholds (`threshold1`, `threshold2`).\n",
        "3. Apply the Probabilistic Hough Line Transform (`cv2.HoughLinesP`) to the Canny edge map. Experiment with the parameters:\n",
        "   * `rho`: Distance resolution (e.g., 1 pixel).\n",
        "   * `theta`: Angle resolution (e.g., `np.pi/180` for 1 degree).\n",
        "   * `threshold`: Minimum number of votes (intersections in Hough accumulator).\n",
        "   * `minLineLength`: Minimum length of a line segment to be detected.\n",
        "   * `maxLineGap`: Maximum allowed gap between points on the same line.\n",
        "4. If lines are detected (`lines` is not None), iterate through the line segments and draw them onto the *original color image* (load it separately) using `cv2.line`. The lines array contains `[[x1, y1, x2, y2]]` for each segment.\n",
        "5. Display the Canny edge map and the original image with detected lines drawn on it.\n",
        "6. Answer the discussion questions.\n"
      ],
      "metadata": {
        "id": "DoZbf3gD4Nos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_tennis_gray = load_image(IMG_PATH_TENNIS, cv2.IMREAD_GRAYSCALE)\n",
        "img_tennis_color = load_image(IMG_PATH_TENNIS, cv2.IMREAD_COLOR) # For drawing\n",
        "\n",
        "\n",
        "img_draw_ex5 = img_tennis_color.copy()\n",
        "\n",
        "# --- Student Code Starts Here ---\n",
        "\n",
        "# 1. Apply Canny Edge Detection (Tune thresholds)\n",
        "\n",
        "canny_low_thresh = None\n",
        "canny_high_thresh = None\n",
        "\n",
        "edges = cv2.Canny(img_tennis_gray, canny_low_thresh, canny_high_thresh)\n",
        "\n",
        "lines_p = None # Initialize lines\n",
        "if edges is not None:\n",
        "    # 2. Apply Probabilistic Hough Line Transform (Tune parameters)\n",
        "    rho_acc = None         # Replace Rho accuracy: 1 pixel\n",
        "    theta_acc = None       # Replace Theta accuracy: 1 degree\n",
        "    hough_thresh = None    # Replace Min votes: Tune this\n",
        "    min_line_len = None    # Replace Min length: Tune this\n",
        "    max_line_gap = None    # Replace Max gap: Tune this\n",
        "\n",
        "    lines_p = cv2.HoughLinesP(edges, rho_acc, theta_acc, hough_thresh,\n",
        "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
        "\n",
        "    # 3. Draw detected lines\n",
        "    if lines_p is not None:\n",
        "        print(f\"Detected {len(lines_p)} line segments. Drawing...\")\n",
        "        for line in lines_p:\n",
        "            x1, y1, x2, y2 = None # Extract coordinates # Replace\n",
        "            cv2.line(img_draw_ex5, (x1, y1), (x2, y2), (0, 0, 255), 2) # Draw red lines\n",
        "    else:\n",
        "        print(\"No line segments detected with current parameters.\")\n",
        "else:\n",
        "    print(\"Canny edge detection failed or produced no edges.\")\n",
        "\n",
        "# --- Student Code Ends Here ---\n",
        "\n",
        "# Display results\n",
        "images_ex4 = [img_tennis_color, edges if edges is not None else np.zeros_like(img_tennis_gray), img_draw_ex5]\n",
        "titles_ex4 = [\"Original Road\", \"Canny Edges\", \"Detected Lines (HoughP)\"]\n",
        "show_images(images_ex4, titles_ex4, 1, 3, main_title=\"Exercise 4: Hough Line Detection\")\n"
      ],
      "metadata": {
        "id": "MigTxv4C4MkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion Questions (Exercise 4):**\n",
        "1. Explain the purpose of applying Canny edge detection *before* the Hough Transform.\n",
        "2. How does changing the `threshold` parameter in `cv2.HoughLinesP` affect the number of lines detected?\n",
        "3. What is the effect of increasing `minLineLength`? What about increasing `maxLineGap`?"
      ],
      "metadata": {
        "id": "wGUlpIg43Fx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Exercise: Refining Image Segmentation\n",
        "\n",
        "Objective: Segment and filter regions of interest from an image using thresholding, morphological operations, and connected component analysis.\n",
        "\n",
        "Image: Use the img_gray_ex3 image (ensure it's loaded as grayscale). If not available, load a grayscale image of your choice with some distinct structures.\n",
        "\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Thresholding:\n",
        "    - Apply cv2.adaptiveThreshold to img_gray_ex3 to create a binary image img_binary. Experiment with the blockSize (e.g., 35, 57, 75) and C (e.g., 5, 8, 10) parameters.\n",
        "    - (Optional): Also try cv2.threshold with cv2.THRESH_OTSU.\n",
        "        Use cv2.THRESH_BINARY_INV if your objects of interest are darker than the background in the original image and you want them white in the mask.\n",
        "2. Morphological operations\n",
        "    - Refine img_binary using cv2.morphologyEx. Start with cv2.MORPH_CLOSE.\n",
        "    - Experiment with different kernel shapes and sizes for the structuring element (e.g., np.ones((H,W), np.uint8)). Try a vertical kernel (e.g., (7,1)), a horizontal kernel (e.g., (1,7)), and a square kernel (e.g., (3,3) or (5,5)).\n",
        "3. Connected Components Analysis\n",
        "    - Find connected regions in img_morph using cv2.connectedComponentsWithStats. This will give you num_labels, a labels matrix, stats, and centroids.\n",
        "4. Region Filtering\n",
        "\n",
        "    - Filter the detected regions based on their properties stored in stats. For example, filter by aspect ratio (height/width) or area (cv2.CC_STAT_AREA).\n",
        "    - Create a new image labels_filtered that only contains the regions meeting your criteria (set others to 0, the background label). The original code filtered out regions where (height / width) < 5 was NOT true (i.e., it kept regions where height/width < 5). Modify this to, for example, keep regions that are significantly taller than they are wide, or regions within a specific area range.\n"
      ],
      "metadata": {
        "id": "w1ynOa76AS6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_gray_opt = load_image(\"images/barcode.png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "8ZHtxQx1ATCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion Questions:**\n",
        "\n",
        "1. Thresholding Impact: How did changing the blockSize and C parameters in cv2.adaptiveThreshold affect your img_binary? When might adaptive thresholding be more beneficial than a global method like Otsu's, and vice-versa?\n",
        "2. Morphology Choices: Explain the effect of using a cv2.MORPH_CLOSE operation. How did different kernel shapes (e.g., vertical vs. square) and sizes influence the img_morph result for your specific image? When would you choose MORPH_OPEN instead?\n",
        "3. Filtering Rationale: Describe the criteria you used for filtering connected components in Step 4. Why did you choose these criteria, and how might they need to change if you were looking for different types of objects in the image?"
      ],
      "metadata": {
        "id": "0Ucj1O-wBiLV"
      }
    }
  ]
}